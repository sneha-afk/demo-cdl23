{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the OpenAI API, [logit bias](https://platform.openai.com/docs/api-reference/chat/create#chat/create-logit_bias) is taken as a mapping of tokens to their bias levels ranging from -100, a potential complete ban of the token, to 100, a potenital guarantee of selection. Lesser magnitude values like -1 or 1 will configure the possibility for the token's \"selection\": the chance it will appear in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representative tokens for certain characters can be obtained from [OpenAI's tokenizer](https://platform.openai.com/tokenizer) or through other helpful programs. \n",
    "\n",
    "Tokenizers are sensitive to capitalization, spaces, and punctuation; it is crucial to consider all possible tokens of certain strings if logit bias is being implemented manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A helpful tokenizer package to is `tiktoken`, check out the project [here](https://github.com/openai/tiktoken)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a team of three, we worked on implementing logit bias on the Python branch by adding a dictionary parameter to `ChatRequestSettings` and `CompleteRequestSettings` and including them in the JSON requests sent to the OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See our [merged pull request #1880](https://github.com/microsoft/semantic-kernel/pull/1880) for the source code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1: `ChefBot`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit bias is part of the offical Python module\n",
    "!python -m pip -q install semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are developing a `ChefBot` program that comes up with delicious recipes for a user while also keeping preferences and allergies in mind. Yum!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user may ask:\n",
    "\n",
    "```bash\n",
    "User:> I want to make a smoothie, pls remember I am allergic to bananas!\n",
    "```\n",
    "\n",
    "Gathering the tokens for \"bananas\" yields `[3820, 15991]`, which should be banned from the outputted recipe. \n",
    "\n",
    "> As discussed earlier, however, to completely ban the tokens would mean having different variations of the string `\"bananas\"`.\n",
    "> I will add these myself, but don't be discouraged if you aren't getting total bans at first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the `ChefBot` chat experience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.connectors.ai.chat_request_settings import ChatRequestSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a chat service\n",
    "\n",
    "# Note: you can download this notebook and run in a directory containing a .env with your OpenAI API key,\n",
    "# or add it manually where the \"key\" string is. Be careful with your secrets!\n",
    "USE_ENV = True\n",
    "if USE_ENV:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "else:\n",
    "    api_key, org_id = \"key\", None\n",
    "\n",
    "# Register the chat service into the kernel\n",
    "openai_chat_completion = OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id)\n",
    "\n",
    "# Ensuring it was instantiated correctly\n",
    "assert openai_chat_completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For more complex use with the kernel and as a semantic function, you can also register it as a skill:\n",
    "> ```python\n",
    "> kernel = sk.Kernel()\n",
    "> prompt_config = sk.PromptTemplateConfig.from_completion_parameters(max_tokens=2000, temperature=0.7, top_p=0.8)\n",
    "> prompt_template = sk.ChatPromptTemplate(\"{{$user_input}}\", kernel.prompt_template_engine, prompt_config)\n",
    "> prompt_template.add_system_message(\"You are a chat bot specializing the culinary arts.\")\n",
    "> function_config = sk.SemanticFunctionConfig(prompt_config, prompt_template)\n",
    "> chat_with_chef = kernel.register_semantic_function(\"ChefBot\", \"Chat\", function_config)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokens must be set with a logit bias of -100 for a total ban. This is done within the `ChatRequestSettings` instance send with the request.\n",
    "\n",
    "> `CompleteRequestSettings` is used in text completion requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = ChatRequestSettings(max_tokens=512, temperature=0.5, top_p=0.8)\n",
    "\n",
    "tokens_to_ban = [3820, 15991, 2271, 35484, 25996, 3958]\n",
    "for token in tokens_to_ban:\n",
    "    settings.token_selection_biases[token] = -100       # no monkey business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up chat history and add the user's request.\n",
    "> In an actual program, this can be done more succinctly using `input()` and some parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"I want to make a smoothie, pls remember I am allergic to bananas!\"\n",
    "\n",
    "chat_messages = list()\n",
    "chat_messages.append((\"user\", user_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User request in one hand, loaded settings in the other, let's get a response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = await openai_chat_completion.complete_chat_async(chat_messages, settings)\n",
    "chat_messages.append((\"assistant\", str(answer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper loop for printing out chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:> I want to make a smoothie, pls remember I am allergic to bananas!\n",
      "\n",
      "ChefBot:> No worries! Here's a delicious smoothie recipe that doesn't include bananas:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of frozen berries (strawberries, blueberries, raspberries, or a mix)\n",
      "- 1 cup of spinach or kale\n",
      "- 1 cup of almond milk (or any other non-dairy milk of your choice)\n",
      "- 1 tablespoon of honey or maple syrup (optional, for added sweetness)\n",
      "- 1 tablespoon of chia seeds (optional, for added nutrition)\n",
      "- Ice cubes (optional, for a colder smoothie)\n",
      "\n",
      "Instructions:\n",
      "1. Add the frozen berries, spinach or kale, almond milk, honey or maple syrup, and chia seeds to a blender.\n",
      "2. Blend on high speed until smooth and creamy. If the mixture is too thick, you can add a little more almond milk to reach your desired consistency.\n",
      "3. Taste the smoothie and adjust the sweetness if needed by adding more honey or maple syrup.\n",
      "4. If you prefer a colder smoothie, add a few ice cubes and blend again until well combined.\n",
      "5. Pour the smoothie into a glass and enjoy!\n",
      "\n",
      "Feel free to customize this recipe by adding other fruits or ingredients that you enjoy. Enjoy your banana-free smoothie!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_chat(msg_list):\n",
    "    for role, msg in msg_list:\n",
    "        if role == \"user\":\n",
    "            print(f\"User:> {msg}\\n\")\n",
    "        else:\n",
    "            print(f\"ChefBot:> {msg}\\n\")\n",
    "\n",
    "print_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... other than the friendly assertion that the recipe does not include bananas, the response was pretty banana-less!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how can you be certain it did not response as such only *because* you said you were allergic to bananas? \n",
    "\n",
    "Confirm by removing it from the prompt and restarting the chat history!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"I want to make a smoothie :)\"\n",
    "\n",
    "chat_messages = list()\n",
    "chat_messages.append((\"user\", user_request))\n",
    "answer = await openai_chat_completion.complete_chat_async(chat_messages, settings)\n",
    "chat_messages.append((\"assistant\", str(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:> I want to make a smoothie :)\n",
      "\n",
      "ChefBot:> Great! Making a smoothie is a fun and healthy way to enjoy a refreshing drink. Here's a simple recipe to get you started:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of your favorite fruits (such as bananas, berries, mango, or pineapple)\n",
      "- 1 cup of liquid (such as milk, almond milk, coconut water, or yogurt)\n",
      "- 1 tablespoon of honey or maple syrup (optional, for added sweetness)\n",
      "- 1 cup of ice cubes\n",
      "\n",
      "Instructions:\n",
      "1. Gather all your ingredients and wash the fruits if necessary.\n",
      "2. Chop the fruits into smaller pieces for easier blending.\n",
      "3. Add the fruits, liquid, sweetener (if using), and ice cubes to a blender.\n",
      "4. Blend everything together on high speed until smooth and creamy. If the consistency is too thick, you can add more liquid.\n",
      "5. Taste the smoothie and adjust the sweetness or thickness according to your preference.\n",
      "6. Pour the smoothie into a glass or a portable bottle.\n",
      "7. You can garnish the smoothie with a sprinkle of chia seeds, shredded coconut, or a few fresh fruit slices if desired.\n",
      "8. Enjoy your homemade smoothie immediately!\n",
      "\n",
      "Feel free to customize your smoothie by adding other ingredients like spinach or kale for extra nutrients, protein powder for a post-workout boost, or a spoonful of nut butter for added creaminess. Have fun experimenting with different flavor combinations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare the response to the same prompt but a new settings instance while all other chat parameters are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_settings = ChatRequestSettings(max_tokens=516, temperature=0.5, top_p=0.8)\n",
    "\n",
    "chat_messages = list()\n",
    "chat_messages.append((\"user\", user_request))\n",
    "answer = await openai_chat_completion.complete_chat_async(chat_messages, blank_settings)\n",
    "chat_messages.append((\"assistant\", str(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:> I want to make a smoothie :)\n",
      "\n",
      "ChefBot:> Great! Making a smoothie is a fun and easy way to enjoy a nutritious and delicious drink. Here's a simple recipe to get you started:\n",
      "\n",
      "Ingredients:\n",
      "- 1 ripe banana\n",
      "- 1 cup of frozen berries (such as strawberries, blueberries, or mixed berries)\n",
      "- 1 cup of milk (dairy or plant-based)\n",
      "- 1 tablespoon of honey or maple syrup (optional, for added sweetness)\n",
      "- 1/2 cup of yogurt (optional, for a creamier texture)\n",
      "- Ice cubes (optional, for a colder smoothie)\n",
      "\n",
      "Instructions:\n",
      "1. Peel the banana and break it into smaller chunks.\n",
      "2. Place the banana chunks, frozen berries, milk, honey or maple syrup, and yogurt (if using) into a blender.\n",
      "3. Blend all the ingredients together until smooth and creamy. If the mixture seems too thick, you can add a little more milk.\n",
      "4. If you prefer a colder smoothie, you can add a few ice cubes and blend again.\n",
      "5. Taste the smoothie and adjust the sweetness or thickness to your liking by adding more honey, milk, or yogurt if desired.\n",
      "6. Once you're satisfied with the consistency and taste, pour the smoothie into a glass and enjoy!\n",
      "\n",
      "Feel free to experiment with different fruits, vegetables, and add-ins like spinach, kale, peanut butter, or protein powder to customize your smoothie to your preferences. Enjoy your homemade smoothie!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Recognize that the LLM's outputs will always have a non-deterministic aspect of it, and even with the greatest logit bias definitions, there may be banned tokens present in the output.\n",
    "\n",
    "Prompt engineering is a tricky practice, and logit bias is just one tool to help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
